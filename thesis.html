<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Harichandana Neralla - Portfolio</title>
    <link rel="stylesheet" href="./css/index.css">
    <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@picocss/pico@1/css/pico.min.css"> -->
</head>

<body>
    <nav class="sidebar">
        <img src="./img/face-logo.png">
        <header>
            <h1>Harichandana Neralla</h1>
            <h3>University of Texas at Dallas</h3>
            <h4>MS in Computer Science <p>(Data Science)</p>
            </h4>
            <h4>
                <p>‚òéÔ∏è Connect:&nbsp;&nbsp;<a href="https://www.linkedin.com/in/harichandana-neralla/"
                        target="_blank">LinkedIn</a> |
                    <a href="https://github.com/harineralla" target="_blank">GitHub</a>
                </p>
                <p>&#128233; Email: <a href="mailto:harichandana.neralla@utdallas.edu">Harichandana-email</a></p>
            </h4>
        </header>
    </nav>

    <main class="main">
        <h2>üìö Projects</h2>
        <section>
            <h3>Automated Code Comment Generation with LLMs</h3>
            <p>Exploring the frontier of automated code documentation, this project dives into leveraging Large Language
                Models (LLMs) for generating insightful comments on code snippets. Employing cutting-edge methods like
                zero-shot learning, in-context learning, and prompt tuning, the study carves a path towards redefining
                code annotation practices.</p>

            <ul>
                <li>Conducted a comparative analysis of LLMs, including LLaMa-2 and PaLM, to assess their efficacy in
                    generating contextually relevant code comments.</li>
                <li>Implemented a blend of zero-shot learning and in-context learning strategies to navigate the
                    complexities of code syntax and semantics without extensive training data.</li>
                <li>Utilized prompt tuning to tailor LLMs' responses, optimizing the balance between informativeness and
                    conciseness in code comments.</li>
                <li>Evaluated model performances across diverse programming languages, highlighting the adaptability and
                    scalability of LLMs in software development contexts.</li>
            </ul>

            <h4>Experimentation with LLMs</h4>
            <p>The project showcases an innovative approach to code comment generation, utilizing LLMs to decipher and
                document code. By examining models like LLaMa-2 and PaLM, the research unveils the potential of AI in
                automating the documentation process, making it more efficient and insightful.</p>

            <figure>
                <img src="data:image/png;base64,[image_experiment_setup_base64]"
                    alt="Experimental Setup and Model Comparison">
                <figcaption>Fig 1: Illustration of Experimental Setup and Model Comparison</figcaption>
            </figure>

            <h4>Key Insights and Outcomes</h4>
            <p>Through meticulous experimentation, the project uncovers the strengths of LLMs in understanding and
                annotating code. Zero-shot learning and in-context learning emerged as pivotal in enabling models to
                generate precise comments, while prompt tuning further refined output quality.</p>

            <figure>
                <img src="data:image/png;base64,[image_key_insights_base64]" alt="Key Insights from LLM Performance">
                <figcaption>Fig 2: Key Insights from LLM Performance on Code Comment Generation</figcaption>
            </figure>

            <p>The findings illuminate the path for future advancements in code documentation, advocating for the
                integration of LLMs into software development workflows. The project not only enhances code readability
                and maintenance but also sets a benchmark for AI's role in software engineering.</p>
        </section>
    </main>




</body>

</html>