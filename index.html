<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Harichandana Neralla - Portfolio</title>
    <link rel="stylesheet" href="./css/index.css">
</head>

<body>
    <nav class="sidebar">
        <!-- style="background-image: url('./img/sidebar-bg.jpeg');" -->
        <!-- <img src="./img/face-logo.png" /> -->
        <header>
            <h1>Harichandana Neralla</h1>
            <div class="university">
                <h3>University of Texas at Dallas</h3>
                <h4>MS in Computer Science <p>(Data Science)</p>
                </h4>
            </div>
            <div class="contact">
                <h4>
                    <p>
                        üìÑ Resume:&nbsp;&nbsp;
                        <a href="https://harineralla.github.io/docs/Harichandana-Neralla-resume.pdf">Resume</a>
                    </p>
                    <p>
                        ‚òéÔ∏è Connect:&nbsp;&nbsp;<a href="https://www.linkedin.com/in/harichandana-neralla/"
                            target="\_blank">LinkedIn</a>
                        |
                        <a href="https://github.com/harineralla" target="\_blank">GitHub</a>
                    </p>
                    <p>
                        &#128233; Email:&nbsp;&nbsp;
                        <a href="mailto:harichandana10899@gmail.com">Harichandana-email</a>
                    </p>
                </h4>
            </div>
        </header>
    </nav>
    <main class="main">
        <section>
            <section>
                <h2>üôãüèª‚Äç‚ôÄÔ∏è Introduction</h2>
                <section>
                    <p style="justify-content: center; padding-top: 0px">
                    <p>
                        Hello, as an enthusiastic and diligent computer science graduate student specializing
                        in Data Science at the University of Texas at Dallas, I am driven by an insatiable curiosity for
                        the
                        transformative power of data. My passion lies in unlocking the invaluable insights hidden within
                        complex
                        datasets, transforming them into comprehensible narratives that drive informed decision-making.
                    </p>
                    <p>
                        With a keen interest in software development, distributed systems and cloud computing, I am
                        actively
                        expanding my horizons to leverage cutting-edge technologies that enable seamless data
                        processing,
                        analysis, and storage at scale. I thrive on the challenge of exploring innovative methods to
                        harness the
                        full potential of data, pushing the boundaries of what is possible.
                    </p>
                    </p>
                </section>
                <section>
                    <!-- <h3>üìö Projects</h3> -->
                    <h2>Projects</h2>
                    <ul class="projects-bullets">
                        <li>
                            <h3>
                                Independent Lab Research: Detecting Security Vunerability and producing software patches
                                using LLMs
                            </h3>
                            This research delved into advancing automated code comment generation through the
                            utilization of Large Language Models (LLMs) and sophisticated techniques such as zero-shot
                            learning, in-context learning, and prompt tuning. By ensembling models from leading research
                            papers and integrating various LLMs including LLaMa, CodeBERT, PaLM, GPT-3.5, GPT-4, and
                            NVIDIA‚Äôs Megatron 530B, the study aimed to enhance code summarization and description
                            generation. Additionally, the project developed a PyTorch distributed training framework
                            optimized for large-scale systems, enabling concurrent, memory-efficient training of deep
                            learning models on NVIDIA CUDA GPUs. Moreover, it explored the generation of Story Intention
                            Graphs (SIG) using LLMs and implemented GraphCNN for encoded representations in
                            autoregressive transformer decoding. Through comprehensive experimentation and evaluation,
                            the research aimed to provide valuable insights into the capabilities of LLMs in software
                            development, ultimately contributing to more efficient and effective code documentation
                            practices.<br />
                            <b>Technologies Used:</b>Technologies Used: Large Language Models (LLMs) such as LLaMa,
                            CodeBERT, PaLM, GPT-3.5, GPT-4, and NVIDIA‚Äôs Megatron 530B, PyTorch, NVIDIA CUDA,
                            GraphCNN.<br />
                            <a href="https://github.com/harineralla/Independent-Studies-Spring2024-UTD">GitHub Link</a>
                        </li>
                        <li>
                            <h3>Analysis of automated code comment generation with zero-shot learning, in-context
                                learning and prompt tuning on LLMs</h3>
                            This project is AI and Software Security which aims to investigate and enhance the automated
                            code comment generation process using Large Language Models (LLMs). Leveraging techniques
                            such as zero-shot learning, in-context learning, and prompt tuning, the project seeks to
                            improve the
                            quality and relevance of generated code comments. Through comprehensive experimentation and
                            evaluation, the research aims to provide valuable insights into the capabilities of LLMs in
                            the context of software development, ultimately contributing to more efficient and effective
                            code documentation practices.<br />
                            <b>Technologies Used:</b>Technologies Used: Large Language Models (LLMs), Natural Language
                            Processing (NLP) Libraries (e.g., Hugging Face Transformers), Programming Languages
                            (Python), Version Control Systems (Git), Experimentation and Evaluation Tools, Documentation
                            and Reporting Tools (e.g., LaTeX, Markdown).<br />
                            <a href="https://github.com/harineralla/automated_code_comment">GitHub Link</a>
                        </li>
                        <li>
                            <h3>Online Shoppers Purchase intension Prediction</h3>
                            This project aimed to develop a predictive model for binary classification, predicting
                            whether a user visiting an e-commerce website would make a transaction. Various machine
                            learning algorithms, including Decision Tree, Support Vector Machine (SVM) with Gaussian
                            kernel, Multi-Layer Perceptron, Random Forest, Gradient Boosting, and Extreme Gradient
                            Boosting (XGBoost), were implemented and analyzed using the Scikit-learn library. The
                            dataset, obtained from the UCI ML repository, comprised 12,330 sessions, with imbalanced
                            classes. Techniques such as feature selection, data preprocessing, and hyperparameter tuning
                            were applied to enhance model performance. The analysis included evaluation metrics such as
                            accuracy, precision, recall, and F1 score, along with cross-validation and visualization
                            techniques to compare the models. The results indicated that the Decision Tree and XGBoost
                            models performed the best, with the 1:3 batch ratio yielding the highest accuracy
                            consistently across algorithms. The final recommendation favored XGBoost for its superior
                            performance in classification tasks on this dataset.<br />
                            <b>Technologies Used:</b>Decision Tree, Support Vector Machine (SVM), Multi-Layer
                            Perceptron, Random Forest, Gradient Boosting, Extreme Gradient Boosting (XGBoost),
                            Scikit-learn, Python.<br />
                            <a href="https://github.com/harineralla/Online-shopping-Intension-Prediction">GitHub
                                Link</a>
                        </li>
                        <li>
                            <h3>LSTM Time Series Prediction for Stock Market Data</h3>
                            I implemented a Time Series Stock Prediction model using Long Short-Term Memory (LSTM)
                            networks on the SP500 dataset. The project aims to forecast future stock prices and trends
                            by analyzing historical data. It features extensive data preprocessing to normalize and
                            prepare the dataset for training and evaluation. Leveraging LSTM architecture, the model
                            captures temporal dependencies effectively, outperforming traditional linear models in
                            accuracy. The technologies employed include Python, TensorFlow for LSTM implementation,
                            Scikit-learn for preprocessing, and analysis of financial data.<br />
                            <b>Technologies Used:</b>Python, TensorFlow, Scikit-learn<br />
                            <a href="https://github.com/harineralla/Stock-Market-Prediction-using-RNN-LSTM-">GitHub
                                Link</a>
                        </li>
                        <li>
                            <h3>
                                NFT Transaction System: A Secure and Efficient Platform for Trading Ethereum-based NFTs
                                with Robust Database Management
                            </h3>
                            I developed the NFT Transaction System (NTS), a web-based application designed for secure
                            and efficient NFT trading on the Ethereum blockchain. The core of this system is its robust
                            relational database design, which ensures seamless data storage and querying. The system
                            handles comprehensive user management, transaction processing, commission handling, and
                            detailed transaction history reporting. It integrates advanced database management practices
                            using PostgreSQL to support scalable and reliable NFT transactions.<br />
                            <a href="https://github.com/harineralla/nft-transaction-system">GitHub Link</a><br />
                            <b>Technologies Used:</b> Spring Boot, Svelte.js, PostgreSQL, Web3j, Java, JavaScript,
                            Docker.<br />
                        </li>
                        <li>
                            <h3>Expression Invariant Features for Face Recognition</h3>
                            I spearheaded the development of an Expression Invariant Face Recognition System (EIFRS),
                            leveraging deep learning techniques such as Convolutional Neural Networks (CNNs) and Support
                            Vector Machines (SVMs). The system addresses the challenge of recognizing individuals
                            accurately despite variations in facial expressions. By intuitively detecting universal
                            expressions like smile, sadness, anger, surprise, and neutral, our model enhances accuracy
                            in face recognition tasks. We conducted experiments to evaluate the effectiveness of
                            different machine learning methods, including SVM with various kernels, after preprocessing
                            and feature extraction using VGG-Face models. The project culminated in a robust system
                            capable of accurately identifying individuals across different facial expressions.<br />
                            <b>Technologies Used:</b>Python, TensorFlow, OpenCV, VGG-Face model, Convolutional Neural
                            Networks (CNNs), Support Vector Machines (SVMs).</br />
                            <a
                                href="https://www.ijeat.org/wp-content/uploads/papers/v9i2/B3099129219.pdf">Publication</a>
                        </li>
                    </ul>
                </section>
                <!-- <section>
            <h2>üõ†Ô∏è Skills</h2>
            <div class="skill-sections">
                <div class="subheading">
                    <p><strong>Languages:</strong> Python, R, Matlab, Objective C, MySQL, Scala.</p>
                </div>
                <div class="subheading">
                    <p>
                        <strong>Deep Learning Libraries:</strong> NumPy, Pandas,
                        Matplotlib, PyTorch, TensorFlow, NLTK, OpenCV, CoreFlow,
                        Sklearn, PySpark, MLlib, Keras.
                    </p>
                </div>
                <div class="subheading">
                    <p>
                        <strong>ML and DL Skills:</strong> Regression, Clustering, SVM,
                        Decision Trees, Na√Øve Bayes, Random Forest, NLP, CNN, RNN, LSTM,
                        GAN, YOLO.
                    </p>
                </div>
                <div class="subheading">
                    <p>
                        <strong>Other Frameworks for Analytics:</strong> Flask, Django,
                        Tableau, Excel, PowerBi, Hadoop, Spark, DataBricks, ETL, AWS
                        Services, Arduino.
                    </p>
                </div>
            </div>
        </section> -->
                <!-- <section style="margin-top: 20px">
            <h3>
                Other Experience
                <a href="/sde-experience.html">Python Full Stack/Software Development Engineer</a>
            </h3>
        </section> -->
                <section>
                    <!-- <h2>üìú Certifications</h2> -->
                    <h2>Certifications</h2>
                    <ul class="prof-experience">
                        <li>AWS Certified ‚Äì Solutions Architect Associate - <a
                                href="https://www.credly.com/badges/1ef68e5e-4946-4e57-ba9c-5b51a3499da/public_url"
                                target="_blank">Credential Link</a></li>
                    </ul>
                </section>

                <section>
                    <!-- <h2>üíº Professional Experience</h2> -->
                    <h2>Professional Experience</h2>
                    <div>
                        <h3>ACS Solutions(now Innova Solutions), India - Software Engineer</h3>
                        <h4>Accenture/ Trend Micro Solutions project</h4>
                        <p>December 2018 ‚Äì July 2022</p>
                        <ul class="prof-experience">
                            <li>Designed and implemented a comprehensive data analytics and visualization tool utilizing
                                React
                                Js, Python and MongoDB.</li>
                            <li>Improved Node.js backend response time 10x by optimizing data handling with MongoDB,
                                ElasticDB
                                and DynamoDB.</li>
                            <li>Digitalized on-prem ETL spark jobs to AWS cloud reduced response time from 4hrs to 2hrs
                                using
                                AWS Glue, and data catalog.</li>
                            <li>Optimized data architecture by migrating all S3 data to a unified data lake house with
                                Databricks integration.</li>
                        </ul>
                    </div>
                    <div>
                        <h4>EWE AG Project</h4>
                        <!-- <p>December 2019 ‚Äì July 2022</p> -->
                        <ul class="prof-experience">
                            <li>Architected and produced multiple trading web applications and microservices using
                                Python, Flask, RESTful APIs, MongoDB, and PostgreSQL for a German trading firm. Wrote
                                comprehensive unit tests with Pytest achieving 97% coverage.</li>
                            <li>Optimized data workflows utilizing RabbitMQ messaging with AMQP, improving cut latency
                                and transaction volume by 2x.</li>
                            <li>Spearheaded the design and development of 6 high-impact UI applications, including
                                pricing and trading dashboards, using React JS, MERN Stack, and state management with
                                Redux, ensuring robustness through Cypress testing.</li>
                            <li>Produced orchestration using Docker and Ansible, and automated scaling the deployment of
                                projects into AWS EC2 instances.</li>
                            <li>Orchestrated Kubernetes clusters for developed microservices, resulting in an increase
                                in system reliability and a significant reduction in downtime.</li>
                            <li>Managed high-traffic ELK stack for log aggregation using Kibana, reducing downtime by
                                50% and enhancing monitoring.</li>
                            <li>Experienced in writing SQL queries and in data analysis, fixing data issues for various
                                facts and dimensions for data warehouse and data marts for star schema and snowflake
                                schema.</li>
                            <li>Boosted developer productivity by 20% by standardizing technical documentation with
                                Confluence wikis and automating infrastructure provisioning through Terraform.</li>
                            <li>Built and managed CI/CD pipelines using Jenkins and GitLab, halving the release cycles
                                and enhancing software delivery speed.</li>
                            <li>Received "One Team" annual award for independently developing web trading dashboards
                                from inception to completion.</li>

                        </ul>
                    </div>
                    <div>
                        <h3>University of Texas at Dallas ‚Äì Graduate Teaching Assistant</h3>
                        <p>August 2023 ‚Äì May 2024</p>
                        <ul>
                            <li>Instructed courses on Database Systems and Data Structures & Algorithms (DSA) for
                                undergraduate students, grading their exams, and assisting professors.</li>
                            <li>Revamped PMClub website aesthetics, resulting in a significant increase in user
                                engagement, attracting 1,000 additional monthly active users.</li>
                            <li>Implemented SEO strategies, enhancing website visibility on search engine results,
                                leading to a significant increase in monthly organic visits.</li>
                            <li>Streamlined API usage, reducing data retrieval times, and significantly enhancing
                                overall user experience.</li>

                        </ul>
                    </div>
                </section>

                <section>
                    <!-- <h2>üë©‚Äçüíº Leadership Experience</h2> -->
                    <h2>Achievements and Activities</h2>
                    <div>
                        <h3>HackDFW by SYTD, Sponsor Challenge Winner</h3>
                        <p>September 2022</p>
                        <ul>
                            <li>Won the Sponsor Challenge with an app aimed at helping teenagers quit smoking/vaping,
                                using
                                React Native and Node Js.</li>
                            <li>Link to project: <a href="https://devpost.com/software/smoke-app"
                                    target="_blank">https://devpost.com/software/smoke-app</a></li>
                        </ul>
                    </div>
                    <div>
                        <h3>KL University, GDSC Member and Member of LINUX Club and Elite Club</h3>
                        <p>September 2018 - December 2019</p>
                    </div>
                </section>
    </main>

    <!-- Modal -->
    <script>
        const projectContent = {
            "https://github.com/your-github-username/thesis.html": "Content for 'Thesis: Detecting Security Vunerability and producing software patches using LLMs'",
            "https://github.com/your-github-username/MLproject.html": "Content for 'Online Shoppers Purchase intension Prediction'",
            "https://github.com/your-github-username/bigdataproject.html": "Content for 'RNN for stock Market prediction'",
            "https://github.com/your-github-username/miniproject.html": "Content for 'Expression Invariant Features for Face Recognition'"
        };

        const modal = document.getElementById("modal");
        const modalBody = document.querySelector(".modal-body");
        const closeBtn = document.querySelector(".close");
        const githubLink = document.getElementById("github-link");
        const projectLinks = document.querySelectorAll(".projects-bullets a");

        const openModal = (event) => {
            event.preventDefault();
            const projectLink = event.target.getAttribute("href");
            const projectGitHubUrl = `https://github.com/your-github-username${projectLink}`;
            const projectTitle = event.target.textContent;

            modalBody.innerHTML = projectContent[projectGitHubUrl] || ""; // Use the content from the object, or an empty string if not found
            githubLink.href = projectGitHubUrl;
            modal.style.display = "block";
        };

        const closeModal = () => {
            modal.style.display = "none";
        };

        projectLinks.forEach((link) => link.addEventListener("click", openModal));
        closeBtn.addEventListener("click", closeModal);
        window.addEventListener("click", (event) => {
            if (event.target === modal) {
                closeModal();
            }
        });
    </script>

</body>

</html>